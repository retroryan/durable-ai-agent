# Temporal Configuration
TEMPORAL_HOST=temporal:7233
TEMPORAL_NAMESPACE=default

# API Configuration  
API_PORT=8000
API_HOST=0.0.0.0
API_URL=http://localhost:8000

# Frontend Configuration
FRONTEND_PORT=3000

# Worker Configuration
WORKER_TASK_QUEUE=durable-ai-agent-tasks

# MCP Server Configuration

# Proxy Mode (Recommended): Route all weather/agriculture services through unified proxy
MCP_PROXY_MODE=true
MCP_PROXY_URL=http://weather-proxy:8000/mcp

# MCP Tool Name Configuration
# Controls whether tool names are prefixed with server names (for proxy) or not (for direct)
MCP_USE_PROXY=true
# URL for MCP connections (same as MCP_PROXY_URL for proxy mode)
MCP_URL=http://weather-proxy:8000/mcp

# Direct Mode (Alternative): Connect to individual MCP services
# Uncomment these lines and set MCP_PROXY_MODE=false to use direct connections
# MCP_PROXY_MODE=false
# MCP_USE_PROXY=false
# MCP_URL=http://forecast-server:7778/mcp  # Or http://historical-server:7779/mcp, etc.
# MCP_FORECAST_SERVER_HOST=forecast-mcp
# MCP_FORECAST_SERVER_PORT=7778
# MCP_FORECAST_SERVER_URL=http://forecast-mcp:7778/mcp
# MCP_HISTORICAL_SERVER_HOST=historical-mcp
# MCP_HISTORICAL_SERVER_PORT=7779
# MCP_HISTORICAL_SERVER_URL=http://historical-mcp:7779/mcp
# MCP_AGRICULTURAL_SERVER_HOST=agricultural-mcp
# MCP_AGRICULTURAL_SERVER_PORT=7780
# MCP_AGRICULTURAL_SERVER_URL=http://agricultural-mcp:7780/mcp

# Tool Configuration
TOOLS_MOCK=true

# Logging
LOG_LEVEL=INFO

# ==============================================================================
# DEMO CONFIGURATION SECTION
# ==============================================================================
# When running the agentic_loop demo with local MCP servers:
#
# 1. Start MCP servers locally:
#    poetry run python scripts/run_mcp_servers.py
#
# 2. Run the demo with these environment overrides:
#    MCP_USE_PROXY=false poetry run python agentic_loop/demo_react_agent.py agriculture
#
# Or uncomment these settings to use local MCP servers by default:
# MCP_USE_PROXY=false
# MCP_FORECAST_URL=http://localhost:7778/mcp
# MCP_HISTORICAL_URL=http://localhost:7779/mcp
# MCP_AGRICULTURAL_URL=http://localhost:7780/mcp
#
# Note: Don't forget to add your LLM provider configuration below!
# ==============================================================================

# LLM Provider Configuration (Required for demos)
# Uncomment and configure ONE of the following providers:

# For Anthropic Claude:
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=your-api-key-here

# For OpenAI:
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your-api-key-here

# For Ollama (local):
# LLM_PROVIDER=ollama
# OLLAMA_MODEL=gemma3:27b
# OLLAMA_BASE_URL=http://localhost:11434

# For Google Gemini:
# LLM_PROVIDER=gemini
# GOOGLE_API_KEY=your-api-key-here